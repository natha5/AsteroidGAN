{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "HSWuwdFI0uqr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CmY_lJmazXLD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rand\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Activation, Conv1D, Conv2D, Dropout\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre-processing\n",
        "\n",
        "Due to the large size of dataset, many columns that are not needed and some rows containing null values have already been dropped"
      ],
      "metadata": {
        "id": "31YHj_tf0rBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "data = data.drop(['class', 'epoch_cal'], axis=1)\n",
        "data = data.dropna()\n",
        "data['neo'] = data['neo'].replace(('Y','N'), (1,0))\n",
        "data['pha'] = data['pha'].replace(('Y','N'), (1,0))\n",
        "\n",
        "#num_classes = data['class'].nunique()\n",
        "#classes = to_categorical(data['class'], num_classes)\n",
        "\n",
        "data = data.astype('float32')\n",
        "data /= 255\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "print(data.info)"
      ],
      "metadata": {
        "id": "NaRAER8R0w2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e65745-df53-475e-c67c-073f9008182a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(131124, 16)\n",
            "<bound method DataFrame.info of         neo  pha         H  diameter    albedo         e         a         q  \\\n",
            "0       0.0  0.0  0.013333  3.683922  0.000353  0.000298  0.010859  0.010034   \n",
            "1       0.0  0.0  0.016471  2.137255  0.000396  0.000902  0.010878  0.008376   \n",
            "2       0.0  0.0  0.020902  0.967043  0.000839  0.001008  0.010464  0.007775   \n",
            "3       0.0  0.0  0.011765  2.060392  0.001658  0.000348  0.009260  0.008439   \n",
            "4       0.0  0.0  0.027059  0.418427  0.001075  0.000749  0.010094  0.008167   \n",
            "...     ...  ...       ...       ...       ...       ...       ...       ...   \n",
            "573686  0.0  0.0  0.061176  0.017612  0.000094  0.000717  0.011518  0.009411   \n",
            "573687  0.0  0.0  0.060000  0.018020  0.000361  0.000289  0.012456  0.011538   \n",
            "573688  0.0  0.0  0.060392  0.016024  0.000455  0.000326  0.012663  0.011610   \n",
            "573689  0.0  0.0  0.064314  0.012820  0.000408  0.000827  0.012432  0.009811   \n",
            "573690  0.0  0.0  0.065882  0.008361  0.000243  0.000899  0.011454  0.008827   \n",
            "\n",
            "               i        om         w        ad         n        tp_cal  \\\n",
            "0       0.041545  0.314924  0.288618  0.011685  0.000839  79138.937500   \n",
            "1       0.136600  0.678528  1.216480  0.013379  0.000837  79140.085938   \n",
            "2       0.050945  0.666084  0.972809  0.013152  0.000887  79141.664062   \n",
            "3       0.028007  0.407101  0.591092  0.010082  0.001065  79139.257812   \n",
            "4       0.021049  0.555180  1.406464  0.012021  0.000936  79216.929688   \n",
            "...          ...       ...       ...       ...       ...           ...   \n",
            "573686  0.109669  0.674466  0.631966  0.013625  0.000768  79137.734375   \n",
            "573687  0.090955  0.168830  0.812197  0.013374  0.000683  79297.695312   \n",
            "573688  0.064425  0.247204  0.285630  0.013716  0.000666  79256.156250   \n",
            "573689  0.052861  0.314412  0.295110  0.015053  0.000685  79256.945312   \n",
            "573690  0.063265  0.714666  1.132945  0.014080  0.000774  79217.289062   \n",
            "\n",
            "             per      moid  \n",
            "0       6.600572  0.006254  \n",
            "1       6.617298  0.004840  \n",
            "2       6.243191  0.004056  \n",
            "3       5.197775  0.004469  \n",
            "4       5.915351  0.004297  \n",
            "...          ...       ...  \n",
            "573686  7.209965  0.005500  \n",
            "573687  8.108079  0.007620  \n",
            "573688  8.311297  0.007947  \n",
            "573689  8.085117  0.006092  \n",
            "573690  7.149632  0.005193  \n",
            "\n",
            "[131124 rows x 16 columns]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ec6d9db84190>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['neo'] = data['neo'].replace(('Y','N'), (1,0))\n",
            "<ipython-input-3-ec6d9db84190>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['pha'] = data['pha'].replace(('Y','N'), (1,0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training parameters\n"
      ],
      "metadata": {
        "id": "Im19QWilH2OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (16,1)\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = 'accuracy'\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 20\n",
        "VERBOSE = 1\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "metadata": {
        "id": "nfLDJUYCNVvI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator model\n",
        "18 outputs as there are 18 columns in the dataset"
      ],
      "metadata": {
        "id": "4yFogldYp9gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator(latent_dim):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Dense(40, activation='relu', input_dim=latent_dim))\n",
        "  model.add(Dense(18, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "594ZrKNrNOVt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator model\n",
        "This is a binary CNN classifier, to determine whether the input is 'real' or not"
      ],
      "metadata": {
        "id": "nfK5IwLMrRPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv1D(64, kernel_size=5, padding='same', activation='relu', input_shape=INPUT_SHAPE))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "yHa3MhT8rQvA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_discriminator()\n",
        "\n",
        "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slp2HkUaOfmN",
        "outputId": "25a5df08-7523-45a7-84d9-8f65391e59ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 16, 64)            384       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16, 1)             65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 449\n",
            "Trainable params: 449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_real = data.head(65000)\n",
        "y_real = np.ones((65000))"
      ],
      "metadata": {
        "id": "15lI4UpzrFUc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate random, fake samples for training discriminator"
      ],
      "metadata": {
        "id": "OZbVrKZ7e_fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fakes():\n",
        "  neo = rand.choice([1,0]) \n",
        "  pha = rand.choice([1,0])\n",
        "  H = rand.uniform(0,10000)\n",
        "  diameter = rand.uniform(0,100000)\n",
        "  albedo = rand.uniform(0,1)\n",
        "  e = rand.uniform(0, 0.002)\n",
        "  a = rand.uniform(0,1)\n",
        "  q = rand.uniform(0,1)\n",
        "  i = rand.uniform(0,1)\n",
        "  om = rand.uniform(0,1)\n",
        "  w = rand.uniform(0,2)\n",
        "  ad = rand.uniform(0,0.05)\n",
        "  n = rand.uniform(0,0.01)\n",
        "  tp_cal = rand.uniform(0,100000)\n",
        "  per = rand.uniform(0,10)\n",
        "  moid = rand.uniform(0,0.1)\n",
        "\n",
        "  X = np.array([[neo, pha, H, diameter, albedo, e, a, q, i, om, w, ad, n, tp_cal, per, moid]])\n",
        "  return X"
      ],
      "metadata": {
        "id": "ZFO_oZ2de-yW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_fake = np.array([[]])\n",
        "for i in range(65000):\n",
        "  # fix below line - needs to add as a new row, not each value from the function as its own separate row\n",
        "  current_fake = generate_fakes()\n",
        "  x_fake = np.append(x_fake, current_fake)\n",
        "\n",
        "y_fake = np.zeros(65000)\n",
        "\n",
        "x_fake = x_fake.reshape(65000,16)\n",
        "print(x_fake.shape)\n",
        "x = pd.DataFrame(x_fake)\n",
        "print(x.shape, x_real.shape)\n",
        "\n",
        "\n",
        "x = np.append(x,x_real)\n",
        "y = pd.DataFrame(pd.Series(y_real))\n",
        "y = pd.concat([y, pd.Series(y_fake)])\n",
        "\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "x = np.reshape(x, (130000,16))\n",
        "\n",
        "print(x.shape, y.shape)\n"
      ],
      "metadata": {
        "id": "AkmvH66zSjMt",
        "outputId": "dfe469e3-5152-4d6f-fb26-038ad5b030fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(65000, 16)\n",
            "(65000, 16) (65000, 16)\n",
            "(2080000,) (130000, 1)\n",
            "(130000, 16) (130000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, y.shape)\n",
        "\n",
        "history = model.fit(x, y, epochs=N_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "id": "9DwYeN-wCuzq",
        "outputId": "3d4dd6e9-6265-44b0-b38f-75f38225694f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(130000, 16) (130000, 1)\n",
            "Epoch 1/20\n",
            "813/813 [==============================] - 4s 4ms/step - loss: 1.9440 - accuracy: 0.8357 - val_loss: 4.8689 - val_accuracy: 0.6544\n",
            "Epoch 2/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8528 - accuracy: 0.8580 - val_loss: 4.8296 - val_accuracy: 0.6723\n",
            "Epoch 3/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8353 - accuracy: 0.8659 - val_loss: 4.8159 - val_accuracy: 0.6806\n",
            "Epoch 4/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8267 - accuracy: 0.8696 - val_loss: 4.8049 - val_accuracy: 0.6840\n",
            "Epoch 5/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8212 - accuracy: 0.8714 - val_loss: 4.7973 - val_accuracy: 0.6846\n",
            "Epoch 6/20\n",
            "813/813 [==============================] - 3s 4ms/step - loss: 1.8178 - accuracy: 0.8723 - val_loss: 4.7972 - val_accuracy: 0.6839\n",
            "Epoch 7/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8151 - accuracy: 0.8733 - val_loss: 4.7934 - val_accuracy: 0.6847\n",
            "Epoch 8/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8132 - accuracy: 0.8739 - val_loss: 4.8119 - val_accuracy: 0.6719\n",
            "Epoch 9/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8128 - accuracy: 0.8740 - val_loss: 4.7916 - val_accuracy: 0.6840\n",
            "Epoch 10/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8111 - accuracy: 0.8746 - val_loss: 4.7902 - val_accuracy: 0.6843\n",
            "Epoch 11/20\n",
            "813/813 [==============================] - 3s 4ms/step - loss: 1.8099 - accuracy: 0.8750 - val_loss: 4.7890 - val_accuracy: 0.6843\n",
            "Epoch 12/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8089 - accuracy: 0.8753 - val_loss: 4.7909 - val_accuracy: 0.6836\n",
            "Epoch 13/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8082 - accuracy: 0.8756 - val_loss: 4.7861 - val_accuracy: 0.6849\n",
            "Epoch 14/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.9869 - accuracy: 0.8643 - val_loss: 3.8356 - val_accuracy: 0.7458\n",
            "Epoch 15/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.9417 - accuracy: 0.8672 - val_loss: 4.7867 - val_accuracy: 0.6840\n",
            "Epoch 16/20\n",
            "813/813 [==============================] - 3s 3ms/step - loss: 1.8075 - accuracy: 0.8760 - val_loss: 4.7880 - val_accuracy: 0.6838\n",
            "Epoch 17/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8068 - accuracy: 0.8763 - val_loss: 4.7849 - val_accuracy: 0.6847\n",
            "Epoch 18/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8063 - accuracy: 0.8764 - val_loss: 4.7845 - val_accuracy: 0.6848\n",
            "Epoch 19/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8059 - accuracy: 0.8766 - val_loss: 4.7856 - val_accuracy: 0.6845\n",
            "Epoch 20/20\n",
            "813/813 [==============================] - 2s 3ms/step - loss: 1.8055 - accuracy: 0.8767 - val_loss: 4.7844 - val_accuracy: 0.6848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting the GAN together"
      ],
      "metadata": {
        "id": "-h1o0Ycc02vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gan(generator, discriminator):\n",
        "  model = Sequential()\n",
        "  model.add(generator)\n",
        "  model.add(discriminator)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=OPTIMIZER)\n",
        "  return model"
      ],
      "metadata": {
        "id": "QSBHHSoV06Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator()\n",
        "discriminator = make_discriminator()\n",
        "gan = make_gan(generator, discriminator)"
      ],
      "metadata": {
        "id": "UNA2v9Mg1_Hw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}